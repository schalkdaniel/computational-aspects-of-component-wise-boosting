---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "files-ridge-vs-linear/"
)
```

# Binary vs. Ridge vs. Individual Linear Base-Learner

## Load compboost

```{r}
Rcpp::compileAttributes("~/repos/compboost")
devtools::load_all( "~/repos/compboost")
```

## Simulate data

```{r, warnings=FALSE}
# Simulate Data:
nclasses = 10L
nsim = 50000L

classes = sample(x = LETTERS, size = nclasses)
gmean = sample(nclasses) * rnorm(1)

idx = sample(x = seq_len(nclasses), size = nsim, replace = TRUE)

x = classes[idx]
y = gmean[idx] + rnorm(nsim)

df_cat = data.frame(x = x, y = y)

library(ggplot2)
ggplot(data = df_cat, aes(x = x, y = y, fill = x)) +
  geom_boxplot(alpha = 0.4, show.legend = FALSE) +
  scale_fill_brewer(palette = "Set1") +
  xlab("Class") +
  ylab("Value") +
  ggtitle("Group Means")
```

## Set parameter for compboost

```{r}
learning_rate = 0.05
iter_max      = 2000L
```

## Fit linear model for each category in feature (current state of the art)

```{r}
cboost_lin = Compboost$new(data = df_cat, target = "y", loss = LossQuadratic$new())
cboost_lin$addBaselearner(feature = "x", id = "category", bl_factory = BaselearnerPolynomial, intercept = FALSE)
cboost_lin$train(iter_max, trace = as.integer(iter_max / 4))
```


## Fit ridge regression on categorical feature

```{r}
response = ResponseRegr$new("mpg", as.matrix(df_cat$y))

cdata_source = CategoricalData$new(df_cat$x, "x")
bl = BaselearnerCategoricalRidge$new(cdata_source, list(df = 3))

factory_list = BlearnerFactoryList$new()
factory_list$registerFactory(bl)

loss_quadratic = LossQuadratic$new()
optimizer = OptimizerCoordinateDescent$new()

log_iterations = LoggerIteration$new(" iterations", TRUE, iter_max)
logger_list = LoggerList$new()
logger_list$registerLogger(log_iterations)

cboost_ridge = Compboost_internal$new(
  response      = response,
  learning_rate = learning_rate,
  stop_if_all_stopper_fulfilled = FALSE,
  factory_list = factory_list,
  loss         = loss_quadratic,
  logger_list  = logger_list,
  optimizer    = optimizer
)
cboost_ridge$train(trace = as.integer(iter_max / 4))
```

## Fit ridge regression on categorical feature with binary base-learner

```{r}
response = ResponseRegr$new("y", as.matrix(df_cat$y))

cdata_source = CategoricalData$new(df_cat$x, "x")

bl_list = lapply(classes, function (cl) BaselearnerCategoricalBinary$new(cdata_source, cl))

factory_list = BlearnerFactoryList$new()
temp = lapply(bl_list, function (bl) factory_list$registerFactory(bl))

loss_quadratic = LossQuadratic$new()
optimizer = OptimizerCoordinateDescent$new()

log_iterations = LoggerIteration$new(" iterations", TRUE, iter_max)
logger_list = LoggerList$new()
logger_list$registerLogger(log_iterations)

cboost_binary = Compboost_internal$new(
  response      = response,
  learning_rate = learning_rate,
  stop_if_all_stopper_fulfilled = FALSE,
  factory_list = factory_list,
  loss         = loss_quadratic,
  logger_list  = logger_list,
  optimizer    = optimizer
)
cboost_binary$train(trace = as.integer(iter_max / 4))
```

## Compare Estimates

```{r, echo=FALSE}
cf_lin = unlist(cboost_lin$getEstimatedCoef())
cf_lin = cf_lin[-length(cf_lin)] + cf_lin[length(cf_lin)]
cf_ridge = as.vector(cboost_ridge$getEstimatedParameter()$x_x) + as.double(cboost_ridge$getOffset())
cf_binary = unlist(cboost_binary$getEstimatedParameter()) + as.double(cboost_binary$getOffset())

knitr::kable(
  data.frame("Real Means" = sort(gmean), "Estimate Ridge" = sort(cf_ridge), "Estimate Binary" = sort(cf_binary), "Estimate Linear (Binary)" = sort(cf_lin))
)
```

## Microbenchmark


```{r, include=FALSE}
nclasses = 20L
nsim = 50000L

classes = sample(x = LETTERS, size = nclasses)
gmean = sample(nclasses) * rnorm(1)

idx = sample(x = seq_len(nclasses), size = nsim, replace = TRUE)

x = classes[idx]
y = gmean[idx] + rnorm(nsim)

df_cat = data.frame(x = x, y = y)


mb = microbenchmark::microbenchmark(
  "linear" = {
   cboost_lin = Compboost$new(data = df_cat, target = "y", loss = LossQuadratic$new())
   cboost_lin$addBaselearner(feature = "x", id = "category", bl_factory = BaselearnerPolynomial, intercept = FALSE)
   cboost_lin$train(iter_max, trace = 0)
  },
  "ridge" = {
   response = ResponseRegr$new("mpg", as.matrix(df_cat$y))

   cdata_source = CategoricalData$new(df_cat$x, "x")
   bl = BaselearnerCategoricalRidge$new(cdata_source, list(df = 3))

   factory_list = BlearnerFactoryList$new()
   factory_list$registerFactory(bl)

   loss_quadratic = LossQuadratic$new()
   optimizer = OptimizerCoordinateDescent$new()

   log_iterations = LoggerIteration$new(" iterations", TRUE, iter_max)
   logger_list = LoggerList$new()
   logger_list$registerLogger(log_iterations)

   cboost = Compboost_internal$new(
     response      = response,
     learning_rate = learning_rate,
     stop_if_all_stopper_fulfilled = FALSE,
     factory_list = factory_list,
     loss         = loss_quadratic,
     logger_list  = logger_list,
     optimizer    = optimizer
   )
   cboost$train(trace = 0)
  },
  "binary" = {
    response = ResponseRegr$new("y", as.matrix(df_cat$y))

    cdata_source = CategoricalData$new(df_cat$x, "x")

    bl_list = lapply(classes, function (cl) BaselearnerCategoricalBinary$new(cdata_source, cl))

    factory_list = BlearnerFactoryList$new()
    temp = lapply(bl_list, function (bl) factory_list$registerFactory(bl))

    loss_quadratic = LossQuadratic$new()
    optimizer = OptimizerCoordinateDescent$new()

    log_iterations = LoggerIteration$new(" iterations", TRUE, iter_max)
    logger_list = LoggerList$new()
    logger_list$registerLogger(log_iterations)

    cboost_binary = Compboost_internal$new(
      response      = response,
      learning_rate = learning_rate,
      stop_if_all_stopper_fulfilled = FALSE,
      factory_list = factory_list,
      loss         = loss_quadratic,
      logger_list  = logger_list,
      optimizer    = optimizer
    )
    cboost_binary$train(trace = 0)
  }, times = 20L
)
```

```{r, echo=FALSE}
knitr::kable(as.data.frame(summary(mb)))
```



